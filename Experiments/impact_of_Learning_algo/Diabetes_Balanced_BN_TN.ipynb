{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/catarina-moreira/causabilityXAi/blob/master/Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJKi9vUWhXI2"
   },
   "source": [
    "# Demystifying Predictive Black-Box Models: An Interpretable Probabilistic Approach\n",
    "\n",
    "Catarina Moreira, Yu-Liang Chou, Mythreyi Velmurugan, Renuka Sindhgatta Rajan, Chun Ouyang, Peter Bruza\n",
    "\n",
    "**Abstract** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:37.785431Z",
     "start_time": "2020-06-28T01:16:37.783104Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "5Arnv2vDgvSv"
   },
   "outputs": [],
   "source": [
    "# Install tensorflow\n",
    "try:\n",
    "    # tensorflow_version only exists in Colab\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:37.789340Z",
     "start_time": "2020-06-28T01:16:37.787259Z"
    }
   },
   "outputs": [],
   "source": [
    "# library to deal with Bayesian Networks\n",
    "#!pip install pyagrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:38.984414Z",
     "start_time": "2020-06-28T01:16:37.791252Z"
    }
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_tabular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.691025Z",
     "start_time": "2020-06-28T01:16:38.985814Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ypF1SQdQh8vx"
   },
   "outputs": [],
   "source": [
    "# for reproduciability reasons:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import auxiliary functions\n",
    "from learning import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.694472Z",
     "start_time": "2020-06-28T01:16:42.692657Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "bisN9ZyOlN0w",
    "outputId": "7e09ce1e-d4d3-48db-de97-cf214a70a5ef"
   },
   "outputs": [],
   "source": [
    "# use only if opening on google colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diabetes Dataset\n",
    "\n",
    "**Context**\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "**Content**\n",
    "The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor variables includes the \n",
    "- number of pregnancies the patient has had, \n",
    "- their BMI, \n",
    "- insulin level, \n",
    "- age,\n",
    "- glucose,\n",
    "- blood pressure,\n",
    "- skin thickness,\n",
    "- Diabetes pedigree function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6F3cADNh_xD"
   },
   "source": [
    "### Checking Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.698234Z",
     "start_time": "2020-06-28T01:16:42.696127Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OUX7Tyc6v023"
   },
   "outputs": [],
   "source": [
    "# path to project folder\n",
    "# please change to your own\n",
    "PATH = \"/Users/catarina/GitHub/causabilityXAi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.707673Z",
     "start_time": "2020-06-28T01:16:42.701655Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "qnF5zKygiH9x",
    "outputId": "a1458040-afec-4812-982c-d95789824fa2"
   },
   "outputs": [],
   "source": [
    "# name of dataset\n",
    "DATASET_NAME = \"diabetes.csv\"\n",
    "\n",
    "# variable containing the class labels in this case the dataset contains:\n",
    "# 0 - if not diabetes\n",
    "# 1 - if diabetes\n",
    "class_var = \"Outcome\"\n",
    "\n",
    "# load dataset\n",
    "dataset_path = PATH + \"datasets/\" + DATASET_NAME\n",
    "data = pd.read_csv( dataset_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.722229Z",
     "start_time": "2020-06-28T01:16:42.710147Z"
    }
   },
   "outputs": [],
   "source": [
    "# features\n",
    "feature_names = data.drop([class_var], axis=1).columns.to_list()\n",
    "\n",
    "# check how balanced the classes are\n",
    "data.groupby(class_var).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.737837Z",
     "start_time": "2020-06-28T01:16:42.723611Z"
    }
   },
   "outputs": [],
   "source": [
    "# balance dataset\n",
    "sampled_data = data.sample(frac=1)\n",
    "sampled_data = sampled_data[ sampled_data[\"Outcome\"] == 0]\n",
    "no_data = sampled_data.sample(frac=1)[0:268]\n",
    "\n",
    "yes_data = data[ data[\"Outcome\"] == 1]\n",
    "\n",
    "balanced_data = [no_data,yes_data]\n",
    "balanced_data = pd.concat(balanced_data)\n",
    "\n",
    "# check how balanced the classes are\n",
    "balanced_data.groupby(class_var).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a Model for the Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.756708Z",
     "start_time": "2020-06-28T01:16:42.739226Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply one hot encoder to data\n",
    "# standardize the input between 0 and 1\n",
    "X, Y, encoder, scaler = encode_data( balanced_data, class_var)\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_classes = len(balanced_data[class_var].unique())\n",
    " \n",
    "flag = False  # DO NOT CHANGE! Data has already been generated. \n",
    "if flag:\n",
    "    # save training, test and validation data\n",
    "    generate_save_training_data( dataset_path, X, Y)\n",
    "    \n",
    "else:\n",
    "    # load existing training data\n",
    "    X_train, Y_train, X_test, Y_test, X_validation, Y_validation= load_training_data( dataset_path )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.761347Z",
     "start_time": "2020-06-28T01:16:42.758216Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate models for grid search\n",
    "if flag:\n",
    "    models = grid_search_model_generator( n_features, n_classes )\n",
    "\n",
    "    # perform grid_search\n",
    "    HISTORY_DICT = perform_grid_search( models, PATH, DATASET_NAME.replace(\".csv\",\"\"), \n",
    "                                   X_train, Y_train, \n",
    "                                   X_validation, Y_validation, X_test, Y_test, \n",
    "                                   batch_size=8, epochs=150 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:42.842205Z",
     "start_time": "2020-06-28T01:16:42.762651Z"
    }
   },
   "outputs": [],
   "source": [
    "path_serialisation_model = PATH + \"training/\" + DATASET_NAME.replace(\".csv\", \"\") + \"/model/\" \n",
    "path_serialisation_histr = PATH + \"training/\" + DATASET_NAME.replace(\".csv\", \"\") + \"/history/\" \n",
    "\n",
    "# the best performing model was obtained with 5 hidden layers with 12 neurons each\n",
    "model_name = \"model_h5_N12\"\n",
    "    \n",
    "if flag:\n",
    "    \n",
    "    # get respective model training history and model\n",
    "    model_history = HISTORY_DICT[ model_name ][0]\n",
    "    model = HISTORY_DICT[ model_name ][1]\n",
    "\n",
    "    # save model and model history to file\n",
    "    save_model_history(  model_history, model_name, path_serialisation_histr )\n",
    "    save_model( model, model_name, path_serialisation_model )\n",
    "else:\n",
    "    model_history = load_model_history( model_name, path_serialisation_histr )\n",
    "    model = load_model( model_name, path_serialisation_model )\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:43.027836Z",
     "start_time": "2020-06-28T01:16:42.843992Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate loaded model on test and training data\n",
    "optim = keras.optimizers.Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "\n",
    "train_loss, train_acc = model.evaluate(X_train, Y_train, verbose=1)\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print('\\n[Accuracy] Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "print('[Loss] Train: %.3f, Test: %.3f' % (train_loss, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:43.031263Z",
     "start_time": "2020-06-28T01:16:43.029594Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot_model_history( model_history, 'Accuracy' )\n",
    "#plot_model_history( model_history, 'Loss' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:43.034654Z",
     "start_time": "2020-06-28T01:16:43.032865Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot ROC curve\n",
    "#plot_ROC_Curve( model, X_test, Y_test, n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for specific datapoints for local evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:43.103868Z",
     "start_time": "2020-06-28T01:16:43.036143Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "local_data_dict = generate_local_predictions( X_test, Y_test, model, scaler, encoder )\n",
    "\n",
    "# wrapping up information\n",
    "true_positives = []\n",
    "true_negatives = []\n",
    "false_positives = []\n",
    "false_negatives = []\n",
    "for instance in local_data_dict:\n",
    "    \n",
    "    if( instance['prediction_type'] == 'TRUE POSITIVE'):\n",
    "        true_positives.append(instance)\n",
    "\n",
    "    if( instance['prediction_type'] == 'TRUE NEGATIVE' ):\n",
    "        true_negatives.append(instance)\n",
    "        \n",
    "    if( instance['prediction_type'] == 'FALSE POSITIVE' ):\n",
    "        false_positives.append(instance)\n",
    "        \n",
    "    if( instance['prediction_type'] == 'FALSE NEGATIVE' ):\n",
    "        false_negatives.append(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Explanations with Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRUE NEGATIVES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:19:08.726879Z",
     "start_time": "2020-06-28T01:19:00.006086Z"
    }
   },
   "outputs": [],
   "source": [
    "label_lst = [\"No\", \"Yes\"]\n",
    "class_var = \"Diabetes?\"\n",
    "\n",
    "for instance in true_negatives[0:5]:\n",
    "\n",
    "    # get instance index\n",
    "    indx = instance['index']\n",
    "    print(\"INDEX = \" + str(indx))\n",
    "    \n",
    "    [bn, inference, infoBN] = generate_BN_explanations(instance, label_lst, feature_names, \n",
    "                                                        class_var, encoder, scaler, model, PATH, DATASET_NAME )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:20:13.783210Z",
     "start_time": "2020-06-28T01:20:02.530547Z"
    }
   },
   "outputs": [],
   "source": [
    "label_lst = [\"No\", \"Yes\"]\n",
    "class_var = \"Diabetes?\"\n",
    "\n",
    "for instance in true_negatives[5:10]:\n",
    "\n",
    "    # get instance index\n",
    "    indx = instance['index']\n",
    "    print(\"INDEX = \" + str(indx))\n",
    "    \n",
    "    [bn, inference, infoBN] = generate_BN_explanations(instance, label_lst, feature_names, \n",
    "                                                        class_var, encoder, scaler, model, PATH, DATASET_NAME )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:20:28.496930Z",
     "start_time": "2020-06-28T01:20:17.456606Z"
    }
   },
   "outputs": [],
   "source": [
    "label_lst = [\"No\", \"Yes\"]\n",
    "class_var = \"Diabetes?\"\n",
    "\n",
    "for instance in true_negatives[10:15]:\n",
    "\n",
    "    # get instance index\n",
    "    indx = instance['index']\n",
    "    print(\"INDEX = \" + str(indx))\n",
    "    \n",
    "    [bn, inference, infoBN] = generate_BN_explanations(instance, label_lst, feature_names, \n",
    "                                                        class_var, encoder, scaler, model, PATH, DATASET_NAME )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:20:40.443647Z",
     "start_time": "2020-06-28T01:20:28.499166Z"
    }
   },
   "outputs": [],
   "source": [
    "label_lst = [\"No\", \"Yes\"]\n",
    "class_var = \"Diabetes?\"\n",
    "\n",
    "for instance in true_negatives[15:20]:\n",
    "\n",
    "    # get instance index\n",
    "    indx = instance['index']\n",
    "    print(\"INDEX = \" + str(indx))\n",
    "    \n",
    "    [bn, inference, infoBN] = generate_BN_explanations(instance, label_lst, feature_names, \n",
    "                                                        class_var, encoder, scaler, model, PATH, DATASET_NAME )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:20:54.603427Z",
     "start_time": "2020-06-28T01:20:41.502698Z"
    }
   },
   "outputs": [],
   "source": [
    "label_lst = [\"No\", \"Yes\"]\n",
    "class_var = \"Diabetes?\"\n",
    "\n",
    "for instance in true_negatives[20:]:\n",
    "\n",
    "    # get instance index\n",
    "    indx = instance['index']\n",
    "    print(\"INDEX = \" + str(indx))\n",
    "    \n",
    "    [bn, inference, infoBN] = generate_BN_explanations(instance, label_lst, feature_names, \n",
    "                                                        class_var, encoder, scaler, model, PATH, DATASET_NAME )\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model for the Unbalanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T01:16:52.707941Z",
     "start_time": "2020-06-28T01:16:37.671Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply one hot encoder to data\n",
    "# standardize the input between 0 and 1\n",
    "X_unb, Y_unb, encoder_unb, scaler = encode_data( data, class_var)\n",
    "\n",
    "n_features = X_unb.shape[1]\n",
    "n_classes = len(data[class_var].unique())\n",
    "\n",
    "flag = False\n",
    "if flag:\n",
    "    # save training, test and validation data\n",
    "    generate_save_training_data( dataset_path + \"_unb\", X_unb, Y_unb)\n",
    "    \n",
    "else:\n",
    "    # load existing training data\n",
    "    X_train_unb, Y_train_unb, X_test_unb, Y_test_unb, X_validation_unb, Y_validation_unb= load_training_data( dataset_path + \"_unb\" )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMi9CxWI4QNMgqjhwSe/hVD",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Diabetes.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
